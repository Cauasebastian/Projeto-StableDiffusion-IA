{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers torch torchvision pipeline transformers accelerate safetensors sentencepiece spaces peft"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fFrFfRGJKqbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Versao do numpy:"
      ],
      "metadata": {
        "id": "Qg-utGbhwk2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.25.2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YiKN6fKguSj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caso tenha problema com o gradio:"
      ],
      "metadata": {
        "id": "Vs4DuC6VwhPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall gradio"
      ],
      "metadata": {
        "id": "0Z9vYIj9tCcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token para Acesso ao stabilityai/stable-diffusion-3.5-large-turbo"
      ],
      "metadata": {
        "id": "YCRHxXTChU6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install huggingface_hub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BOQQD554frNC",
        "outputId": "559b0164-2ecb-4ed3-a9bf-656afd2800de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"\")\n"
      ],
      "metadata": {
        "id": "Me1Fr_EWfsw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "iDCm8kpUKgxq",
        "outputId": "eafa241d-2902-4d1d-f578-8f72ec00d775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Keyword arguments {'add_watermarker': False} are not expected by StableDiffusionPipeline and will be ignored.\n",
            "Loading pipeline components...: 100%|██████████| 7/7 [00:20<00:00,  2.92s/steps]\n",
            "Keyword arguments {'add_watermarker': False} are not expected by StableDiffusionPipeline and will be ignored.\n",
            "Loading pipeline components...: 100%|██████████| 6/6 [00:20<00:00,  3.44s/steps]\n",
            "/usr/local/lib/python3.10/dist-packages/spaces/zero/decorator.py:72: UserWarning: `enable_queue` parameter is now ignored and always set to `True`\n",
            "  warnings.warn(\"`enable_queue` parameter is now ignored and always set to `True`\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f58c9b6b1b999e47a9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f58c9b6b1b999e47a9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import uuid\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import spaces\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "from typing import Tuple\n",
        "\n",
        "css = '''\n",
        ".gradio-container{max-width: 575px !important}\n",
        "h1{text-align:center}\n",
        "footer {\n",
        "    visibility: hidden\n",
        "}\n",
        "'''\n",
        "\n",
        "DESCRIPTIONXX = \"\"\"## Geração de Imagem com IA Disciplina de PI4\"\"\"\n",
        "\n",
        "examples = [\n",
        "    \"A futuristic cityscape with neon lights and flying cars, cyberpunk theme, 4k, ultra-detailed --v 6.0 --style raw5\",\n",
        "    \"A majestic lion standing on a rocky cliff during sunset, hyper-realistic, 4K resolution --v 6.0 --style raw5\",\n",
        "    \"A cozy winter cabin with a fireplace glowing warmly, snow falling outside, peaceful atmosphere --ar 16:9 --v 6.0 --style raw5\",\n",
        "    \"A surreal dreamscape with floating islands and vibrant flowers, ethereal theme, vibrant colors --v 6.0 --style raw5\",\n",
        "]\n",
        "\n",
        "MODEL_OPTIONS = {\n",
        "    \"Stable Diffusion 1.5\": \"runwayml/stable-diffusion-v1-5\",\n",
        "    \"Stable Diffusion 2.1\": \"stabilityai/stable-diffusion-2-1\",\n",
        "    # Outros modelos devem ser habilitados manualmente\n",
        "\n",
        "    # \"Stable Diffusion 3.5-large-turbo\": \"stabilityai/stable-diffusion-3-5-large-turbo\",\n",
        "    # \"LIGHTNING V5.0\": \"SG161222/RealVisXL_V5.0_Lightning\",\n",
        "    # \"LIGHTNING V4.0\": \"SG161222/RealVisXL_V4.0_Lightning\",\n",
        "}\n",
        "\n",
        "MAX_IMAGE_SIZE = int(os.getenv(\"MAX_IMAGE_SIZE\", \"4096\"))\n",
        "USE_TORCH_COMPILE = os.getenv(\"USE_TORCH_COMPILE\", \"0\") == \"1\"\n",
        "ENABLE_CPU_OFFLOAD = os.getenv(\"ENABLE_CPU_OFFLOAD\", \"0\") == \"1\"\n",
        "BATCH_SIZE = int(os.getenv(\"BATCH_SIZE\", \"1\"))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "style_list = [\n",
        "    {\n",
        "        \"name\": \"3840 x 2160\",\n",
        "        \"prompt\": \"hyper-realistic 8K image of {prompt}. ultra-detailed, lifelike, high-resolution, sharp, vibrant colors, photorealistic\",\n",
        "        \"negative_prompt\": \"cartoonish, low resolution, blurry, simplistic, abstract, deformed, ugly\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"2560 x 1440\",\n",
        "        \"prompt\": \"hyper-realistic 4K image of {prompt}. ultra-detailed, lifelike, high-resolution, sharp, vibrant colors, photorealistic\",\n",
        "        \"negative_prompt\": \"cartoonish, low resolution, blurry, simplistic, abstract, deformed, ugly\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"HD+\",\n",
        "        \"prompt\": \"hyper-realistic 2K image of {prompt}. ultra-detailed, lifelike, high-resolution, sharp, vibrant colors, photorealistic\",\n",
        "        \"negative_prompt\": \"cartoonish, low resolution, blurry, simplistic, abstract, deformed, ugly\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Style Zero\",\n",
        "        \"prompt\": \"{prompt}\",\n",
        "        \"negative_prompt\": \"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "styles = {k[\"name\"]: (k[\"prompt\"], k[\"negative_prompt\"]) for k in style_list}\n",
        "DEFAULT_STYLE_NAME = \"3840 x 2160\"\n",
        "STYLE_NAMES = list(styles.keys())\n",
        "\n",
        "def apply_style(style_name: str, positive: str, negative: str = \"\") -> Tuple[str, str]:\n",
        "    if style_name in styles:\n",
        "        p, n = styles.get(style_name, styles[DEFAULT_STYLE_NAME])\n",
        "    else:\n",
        "        p, n = styles[DEFAULT_STYLE_NAME]\n",
        "\n",
        "    if not negative:\n",
        "        negative = \"\"\n",
        "    return p.replace(\"{prompt}\", positive), n + negative\n",
        "\n",
        "def load_and_prepare_model(model_id):\n",
        "    if model_id == \"stabilityai/stable-diffusion-3.5-large-turbo\":\n",
        "        pipe = DiffusionPipeline.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "        ).to(device)\n",
        "    else:\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "            use_safetensors=True,\n",
        "            add_watermarker=False,\n",
        "        ).to(device)\n",
        "        pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "    if USE_TORCH_COMPILE:\n",
        "        pipe.compile()\n",
        "\n",
        "    if ENABLE_CPU_OFFLOAD:\n",
        "        pipe.enable_model_cpu_offload()\n",
        "\n",
        "    return pipe\n",
        "\n",
        "# Preload and compile both models\n",
        "models = {key: load_and_prepare_model(value) for key, value in MODEL_OPTIONS.items()}\n",
        "\n",
        "MAX_SEED = np.iinfo(np.int32).max\n",
        "\n",
        "def save_image(img):\n",
        "    unique_name = str(uuid.uuid4()) + \".png\"\n",
        "    img.save(unique_name)\n",
        "    return unique_name\n",
        "\n",
        "def randomize_seed_fn(seed: int, randomize_seed: bool) -> int:\n",
        "    if randomize_seed:\n",
        "        seed = random.randint(0, MAX_SEED)\n",
        "    return seed\n",
        "\n",
        "@spaces.GPU(duration=60, enable_queue=True)\n",
        "def generate(\n",
        "    model_choice: str,\n",
        "    prompt: str,\n",
        "    negative_prompt: str = \"\",\n",
        "    use_negative_prompt: bool = False,\n",
        "    style_selection: str = DEFAULT_STYLE_NAME,\n",
        "    seed: int = 1,\n",
        "    width: int = 1024,\n",
        "    height: int = 1024,\n",
        "    guidance_scale: float = 3,\n",
        "    num_inference_steps: int = 25,\n",
        "    randomize_seed: bool = False,\n",
        "    use_resolution_binning: bool = True,\n",
        "    num_images: int = 1,\n",
        "    progress=gr.Progress(track_tqdm=True),\n",
        "):\n",
        "    global models\n",
        "    pipe = models[model_choice]\n",
        "\n",
        "    seed = int(randomize_seed_fn(seed, randomize_seed))\n",
        "    generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "    prompt, negative_prompt = apply_style(style_selection, prompt, negative_prompt)\n",
        "\n",
        "    options = {\n",
        "        \"prompt\": [prompt] * num_images,\n",
        "        \"negative_prompt\": [negative_prompt] * num_images if use_negative_prompt else None,\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "        \"guidance_scale\": guidance_scale,\n",
        "        \"num_inference_steps\": num_inference_steps,\n",
        "        \"generator\": generator,\n",
        "        \"output_type\": \"pil\",\n",
        "    }\n",
        "\n",
        "    if use_resolution_binning:\n",
        "        options[\"use_resolution_binning\"] = True\n",
        "\n",
        "    images = []\n",
        "    for i in range(0, num_images, BATCH_SIZE):\n",
        "        batch_options = options.copy()\n",
        "        batch_options[\"prompt\"] = options[\"prompt\"][i:i+BATCH_SIZE]\n",
        "        if \"negative_prompt\" in batch_options:\n",
        "            batch_options[\"negative_prompt\"] = options[\"negative_prompt\"][i:i+BATCH_SIZE]\n",
        "        images.extend(pipe(**batch_options).images)\n",
        "\n",
        "    image_paths = [save_image(img) for img in images]\n",
        "    return image_paths, seed\n",
        "\n",
        "# Frontend\n",
        "with gr.Blocks(css=css, theme=\"bethecloud/storj_theme\") as demo:\n",
        "    gr.Markdown(DESCRIPTIONXX)\n",
        "    with gr.Row():\n",
        "        prompt = gr.Text(\n",
        "            label=\"Prompt\",\n",
        "            show_label=False,\n",
        "            max_lines=1,\n",
        "            placeholder=\"Adicione um texto para gerar a imagem\",\n",
        "            container=False,\n",
        "        )\n",
        "        run_button = gr.Button(\"Gerar\", scale=0)\n",
        "    result = gr.Gallery(label=\"Result\", columns=1, show_label=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        model_choice = gr.Dropdown(\n",
        "            label=\"Seleção de modelo⬇️\",\n",
        "            choices=list(MODEL_OPTIONS.keys()),\n",
        "            value=\"Stable Diffusion 2.1\"\n",
        "        )\n",
        "\n",
        "    with gr.Accordion(\"Explicação dos parametros\", open=False, visible=True):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### Explicação do Modelo e Parâmetros\n",
        "\n",
        "        - **Modelo**: O modelo Stable Diffusion é uma rede neural que gera imagens a partir de descrições textuais. O modelo é baseado em difusão e usa uma técnica chamada \"guidance\" para gerar imagens mais relevantes para o prompt fornecido.\n",
        "\n",
        "        - **Prompt**: O texto fornecido descreve o que você deseja na imagem. Quanto mais detalhado o prompt, mais específica será a imagem gerada.\n",
        "\n",
        "        - **Prompt Negativo**: Descreve o que você **não** quer na imagem. Por exemplo, \"sem ruídos\", \"sem deformações\".\n",
        "\n",
        "        - **Seed**: Um número que determina a aleatoriedade da geração. Usar a mesma seed com o mesmo prompt gera a mesma imagem.\n",
        "\n",
        "        - **Estilo**: Ajusta o estilo da imagem gerada (resolução, detalhamento, etc.).\n",
        "\n",
        "        - **Escalamento de orientação**: Controla a intensidade com que o modelo segue o prompt. Um valor maior resulta em uma imagem mais fiel ao texto, enquanto um valor menor pode ser mais criativo.\n",
        "\n",
        "        - **Passos de Inferência**: Determina quantos passos o modelo tomará para gerar a imagem. Mais passos podem resultar em uma imagem de melhor qualidade, mas são mais lentos.\n",
        "        \"\"\")\n",
        "\n",
        "    with gr.Accordion(\"Opções Avançadas\", open=False, visible=True):\n",
        "        style_selection = gr.Radio(\n",
        "            show_label=True,\n",
        "            container=True,\n",
        "            interactive=True,\n",
        "            choices=STYLE_NAMES,\n",
        "            value=DEFAULT_STYLE_NAME,\n",
        "            label=\"Estilo\",\n",
        "        )\n",
        "        num_images = gr.Slider(\n",
        "            label=\"Número de Imagens\",\n",
        "            minimum=1,\n",
        "            maximum=5,\n",
        "            step=1,\n",
        "            value=1,\n",
        "        )\n",
        "        with gr.Row():\n",
        "           with gr.Column(scale=1):\n",
        "                use_negative_prompt = gr.Checkbox(label=\"Use negative prompt\", value=True)\n",
        "                negative_prompt = gr.Text(\n",
        "                    label=\"Negative prompt\",\n",
        "                    max_lines=5,\n",
        "                    lines=4,\n",
        "                    placeholder=\"Enter a negative prompt\",\n",
        "                    value=\"(deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, (mutated hands and fingers:1.4), disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation\",\n",
        "                    visible=True,\n",
        "                )\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                randomize_seed = gr.Checkbox(value=False, label=\"Seed aleatória?\")\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                seed = gr.Slider(label=\"Seed\", value=1, minimum=0, maximum=MAX_SEED)\n",
        "            with gr.Column(scale=1):\n",
        "                guidance_scale = gr.Slider(\n",
        "                    label=\"Escalamento de Orientação\",\n",
        "                    minimum=0,\n",
        "                    maximum=30,\n",
        "                    step=0.1,\n",
        "                    value=7.5,\n",
        "                )\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                num_inference_steps = gr.Slider(\n",
        "                    label=\"Passos de Inferência\",\n",
        "                    minimum=1,\n",
        "                    maximum=100,\n",
        "                    step=1,\n",
        "                    value=25,\n",
        "                )\n",
        "            with gr.Column(scale=1):\n",
        "                width = gr.Slider(\n",
        "                    label=\"Largura (px)\",\n",
        "                    minimum=512,\n",
        "                    maximum=MAX_IMAGE_SIZE,\n",
        "                    value=1024,\n",
        "                    step=128,\n",
        "                )\n",
        "                height = gr.Slider(\n",
        "                    label=\"Altura (px)\",\n",
        "                    minimum=512,\n",
        "                    maximum=MAX_IMAGE_SIZE,\n",
        "                    value=1024,\n",
        "                    step=128,\n",
        "                )\n",
        "    with gr.Accordion(\"Explicação dos Modelos\", open=False, visible=True):\n",
        "        gr.Markdown(\"\"\"\n",
        "    ### Explicação dos Modelos de Stable Diffusion e Lightning\n",
        "\n",
        "    - **Stable Diffusion 1.5**: Este modelo é uma versão anterior e ainda muito popular do Stable Diffusion. Ele é projetado para gerar imagens com boa qualidade e velocidade. A ênfase está em um equilíbrio entre a fidelidade ao prompt e a criatividade. Ideal para gerar imagens com um estilo mais clássico e bem definido.\n",
        "\n",
        "    - **Stable Diffusion 2.1**: Esta versão apresenta melhorias significativas em relação à 1.5, incluindo uma maior capacidade de gerar imagens mais nítidas e detalhadas, com um melhor controle sobre a composição e os elementos da imagem. O modelo 2.1 é mais refinado em termos de geração de paisagens e cenas realistas, além de ser mais robusto em relação a prompts mais complexos.\n",
        "\n",
        "    - **Stable Diffusion 3.5-large-turbo (opcional)**: A versão 3.5, embora não esteja habilitada no código, é uma versão mais recente que traz aprimoramentos no entendimento semântico dos prompts, resultando em imagens ainda mais realistas e alinhadas com descrições mais abstratas. Este modelo é adequado para casos onde a precisão na interpretação do prompt é crucial. A principal vantagem é a geração de imagens com maior fidelidade a detalhes complexos e relações contextuais.\n",
        "\n",
        "    - **Lightning V4.0 (opcional)**: Este modelo, com aproximadamente 1,5 bilhões a 2 bilhões de parâmetros, é uma versão avançada da arquitetura de difusão, capaz de gerar imagens de alta qualidade com maior precisão no alinhamento dos elementos do prompt. Ele é otimizado para fornecer mais controle sobre os detalhes das imagens e é adequado para situações onde se deseja mais realismo e precisão nas imagens geradas.\n",
        "\n",
        "    - **Lightning V5.0 (opcional)**: Com 2 bilhões a 3 bilhões de parâmetros, o Lightning V5.0 oferece uma qualidade excepcional na geração de imagens, sendo capaz de produzir imagens altamente realistas e detalhadas. O modelo é ideal para geração de imagens com maior complexidade e fidelidade ao prompt. A sua arquitetura avançada permite uma compreensão mais refinada de descrições complexas e uma geração de imagens muito mais fiel e precisa, com resultados de alta resolução e detalhes.\n",
        "\n",
        "    ### Como os Modelos Afetam os Resultados:\n",
        "\n",
        "    - **Fidelidade ao Prompt**: Modelos mais novos, como o 2.1, 3.5, Lightning V4.0 e V5.0, tendem a gerar imagens mais detalhadas e alinhadas com a descrição textual fornecida, resultando em maior fidelidade ao prompt. Modelos como o **Lightning V5.0** apresentam uma excelente capacidade de gerar imagens altamente precisas, refletindo bem as nuances do texto fornecido.\n",
        "\n",
        "    - **Criatividade vs. Precisão**: Modelos mais antigos, como o 1.5, podem ser mais criativos e gerar imagens mais artísticas e imprevisíveis, enquanto os modelos mais recentes e maiores (como o **Lightning V5.0**) tendem a ser mais precisos, com um maior foco na criação de imagens realistas e fiéis ao prompt.\n",
        "\n",
        "    - **Desempenho e Velocidade**: O modelo **Stable Diffusion 1.5** pode ser mais rápido em termos de desempenho, especialmente para imagens simples, enquanto modelos mais avançados como o **Lightning V5.0** ou **Stable Diffusion 2.1** podem gerar imagens mais refinadas, porém com um custo computacional maior, resultando em um tempo de processamento mais longo e maior demanda por recursos (memória e poder de GPU).\n",
        "\n",
        "    ### Tamanho dos Modelos e Parâmetros:\n",
        "\n",
        "    - **Stable Diffusion 1.5**: Aproximadamente **890 milhões** de parâmetros. Ideal para imagens com estilo clássico e boa velocidade de geração.\n",
        "    - **Stable Diffusion 2.1**: Aproximadamente **1,2 bilhões** de parâmetros. Oferece maior detalhamento, controle e refinamento em relação ao 1.5.\n",
        "    - **Stable Diffusion 3.5**: Aproximadamente **1,28 bilhões** de parâmetros. Melhor para geração de imagens com precisão em detalhes complexos e abstrações.\n",
        "    - **Lightning V4.0**: Aproximadamente **1,5 bilhões a 2 bilhões** de parâmetros. Melhor controle sobre a composição e maior realismo nas imagens geradas.\n",
        "    - **Lightning V5.0**: Aproximadamente **2 bilhões a 3 bilhões** de parâmetros. Excelente para imagens com alta fidelidade e resolução, oferecendo precisão e realismo excepcionais.\n",
        "\n",
        "    O número de parâmetros de cada modelo afeta a **qualidade da imagem gerada**, a **fidelidade ao prompt**, e o **tempo de processamento**. Modelos maiores, como os **Lightning V5.0** e **Stable Diffusion 3.5**, tendem a gerar imagens mais realistas e detalhadas, mas exigem mais poder computacional para processar as imagens.\n",
        "\n",
        "    \"\"\")\n",
        "\n",
        "    # Generate\n",
        "    run_button.click(\n",
        "        fn=generate,\n",
        "        inputs=[\n",
        "            model_choice,\n",
        "            prompt,\n",
        "            negative_prompt,\n",
        "            use_negative_prompt,\n",
        "            style_selection,\n",
        "            seed,\n",
        "            width,\n",
        "            height,\n",
        "            guidance_scale,\n",
        "            num_inference_steps,\n",
        "            randomize_seed,\n",
        "            num_images,\n",
        "        ],\n",
        "        outputs=[result, seed],\n",
        "    )\n",
        "\n",
        "\n",
        "demo.queue().launch()\n"
      ]
    }
  ]
}